{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 11:22:55.275284: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Rescaling\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv3D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers, optimizers, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import ast\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.saving import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/s7f5w3y14tjdxlssm2bbvqjc0000gn/T/ipykernel_47744/3215131929.py:5: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  traindfdum = pd.get_dummies(traindf['labels'].apply(pd.Series).stack()).sum(level=0)\n"
     ]
    }
   ],
   "source": [
    "# Reading and preparing the dataframe\n",
    "traindf = pd.read_csv('ODIR-5K_Training_Preprocess.csv')\n",
    "traindf = traindf[['ID', 'labels']]\n",
    "traindf['labels'] = traindf['labels'].apply(lambda x: ast.literal_eval(x))\n",
    "traindfdum = pd.get_dummies(traindf['labels'].apply(pd.Series).stack()).sum(level=0)\n",
    "traindf = pd.concat([traindf, traindfdum], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels from A, C,D, G, H, M, n and O to a column of lists\n",
    "traindf['coded labels'] = traindf.apply(lambda x: [x['A'], x['C'], x['D'], x['G'], x['H'], x['M'], x['N'], x['O']], axis=1)\n",
    "# traindf['coded labels'] = traindf.apply(lambda x: str(x['A'] + x['C'] + x['D'] + x['G'] + x['H'] + x['M'] + x['N'] + x['O']_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>labels</th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>coded labels</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>[C]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0_left_[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>[N]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>0_right_[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_left.jpg</td>\n",
       "      <td>[N]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>1_left_[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_right.jpg</td>\n",
       "      <td>[N]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>1_right_[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_left.jpg</td>\n",
       "      <td>[D, O]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>2_left_[0, 0, 1, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>4689_right.jpg</td>\n",
       "      <td>[N]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>4689_right_[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>4690_left.jpg</td>\n",
       "      <td>[D]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4690_left_[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>4690_right.jpg</td>\n",
       "      <td>[D]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4690_right_[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>4784_left.jpg</td>\n",
       "      <td>[A, H]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>4784_left_[1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>4784_right.jpg</td>\n",
       "      <td>[A, H]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>4784_right_[1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  labels  A  C  D  G  H  M  N  O  \\\n",
       "0         0_left.jpg     [C]  0  1  0  0  0  0  0  0   \n",
       "1        0_right.jpg     [N]  0  0  0  0  0  0  1  0   \n",
       "2         1_left.jpg     [N]  0  0  0  0  0  0  1  0   \n",
       "3        1_right.jpg     [N]  0  0  0  0  0  0  1  0   \n",
       "4         2_left.jpg  [D, O]  0  0  1  0  0  0  0  1   \n",
       "...              ...     ... .. .. .. .. .. .. .. ..   \n",
       "6995  4689_right.jpg     [N]  0  0  0  0  0  0  1  0   \n",
       "6996   4690_left.jpg     [D]  0  0  1  0  0  0  0  0   \n",
       "6997  4690_right.jpg     [D]  0  0  1  0  0  0  0  0   \n",
       "6998   4784_left.jpg  [A, H]  1  0  0  0  1  0  0  0   \n",
       "6999  4784_right.jpg  [A, H]  1  0  0  0  1  0  0  0   \n",
       "\n",
       "                  coded labels                                 Name  \n",
       "0     [0, 1, 0, 0, 0, 0, 0, 0]      0_left_[0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "1     [0, 0, 0, 0, 0, 0, 1, 0]     0_right_[0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "2     [0, 0, 0, 0, 0, 0, 1, 0]      1_left_[0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "3     [0, 0, 0, 0, 0, 0, 1, 0]     1_right_[0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "4     [0, 0, 1, 0, 0, 0, 0, 1]      2_left_[0, 0, 1, 0, 0, 0, 0, 1]  \n",
       "...                        ...                                  ...  \n",
       "6995  [0, 0, 0, 0, 0, 0, 1, 0]  4689_right_[0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "6996  [0, 0, 1, 0, 0, 0, 0, 0]   4690_left_[0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "6997  [0, 0, 1, 0, 0, 0, 0, 0]  4690_right_[0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "6998  [1, 0, 0, 0, 1, 0, 0, 0]   4784_left_[1, 0, 0, 0, 1, 0, 0, 0]  \n",
       "6999  [1, 0, 0, 0, 1, 0, 0, 0]  4784_right_[1, 0, 0, 0, 1, 0, 0, 0]  \n",
       "\n",
       "[7000 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove jpg extension from ID column and make this the Name column\n",
    "traindf['Name'] = traindf['ID'].apply(lambda x: os.path.splitext(x)[0])\n",
    "traindf['Name'] = traindf['Name'].str.cat(traindf['coded labels'].astype(str), sep =\"_\")\n",
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming all files\n",
    "directory = './ODIR-5K_Training_Dataset/'\n",
    "for item in range(len(traindf['ID'])):\n",
    "    os.rename(directory + traindf['ID'][item], directory + traindf['Name'][item] + '.jpg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './ODIR-5K_Training_Dataset/'\n",
    "test_dir = './ODIR-5K_Testing_Images/'\n",
    "train_img = [os.path.join(train_dir, i) for i in os.listdir(train_dir)]\n",
    "test_img = [os.path.join(test_dir, i) for i in os.listdir(test_dir)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_list):\n",
    "    X = []  # images\n",
    "    y = []  # labels (0 for Normal or 1 for Pneumonia)\n",
    "    pattern = r'\\[([\\d,\\s]+)\\]'\n",
    "\n",
    "    for image in tqdm(image_list):\n",
    "        try:\n",
    "            img = cv2.imread(image)\n",
    "            img = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_CUBIC)\n",
    "            # convert image to 2D to 3D\n",
    "            # img = np.dstack([img, img, img])\n",
    "            # convrt greyscale image to RGB\n",
    "            # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Normalalize Image\n",
    "            img = img.astype(np.float32) / 255.\n",
    "            X.append(img)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        match = re.search(pattern, image)\n",
    "        extracted_list = match.group(1).split(',')\n",
    "        extracted_list = [int(i) for i in extracted_list]\n",
    "        y.append(extracted_list)\n",
    "\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess_image(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "k = 1\n",
    "for i in range(4):\n",
    "    a = fig.add_subplot(1, 4, k)\n",
    "    plt.imshow(X_train[i])\n",
    "    k = k + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=(500/3500), random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train, dtype=np.float32)\n",
    "y_train = np.asarray(y_train, dtype=np.float32)\n",
    "\n",
    "X_val = np.asarray(X_validation, dtype=np.float32)\n",
    "y_val = np.asarray(y_validation, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=5,\n",
    "                                     horizontal_flip=True,\n",
    "                                     width_shift_range=0.5,\n",
    "                                     height_shift_range=0.5,\n",
    "                                     shear_range=0.5,\n",
    "                                     zoom_range=0.5,\n",
    "                                    fill_mode='nearest'\n",
    "                                    )\n",
    "#Fitting the Image Generator defined above to the X train data set\n",
    "train_generator.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = IMG_SHAPE)\n",
    "base_model.trainable = False\n",
    "model= Sequential()\n",
    "model.add(Rescaling(1./255,input_shape = IMG_SHAPE))\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=('relu'))) \n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(8,activation=('sigmoid')))\n",
    "\n",
    "# Sanity check\n",
    "print(f\"\\nModel input shape:\\n{model.input_shape}\\nModel output shape:\\n\"\\\n",
    "f\"{model.output_shape}\\n\\n\\nModel summary:\") \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is saved at the end of every epoch, if it's the best seen so far.\n",
    "checkpoint_filepath = './Checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the hyperparameters\n",
    "\n",
    "batch_size= 2**6\n",
    "initial_epochs=5 #15\n",
    "learn_rate=0.001\n",
    "adam = Adam(learning_rate=learn_rate)\n",
    "\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(X_train, y_train, batch_size= batch_size),\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=(X_val,y_val),\n",
    "                    steps_per_epoch= 20, #len(X_train)/batch_size,\n",
    "                    validation_steps=len(X_val),\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "# _ , accuracy = model.evaluate(x=X_test,y=y_test,batch_size= batch_size,verbose=1)\n",
    "# print(f'Model accuracy on test set: {round(accuracy,3)*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
