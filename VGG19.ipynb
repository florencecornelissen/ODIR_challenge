{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 10:16:52.372562: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Rescaling\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv3D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers, optimizers, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import ast\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.saving import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./Datasets/X_train.npy')\n",
    "X_test = np.load('./Datasets/X_val.npy')\n",
    "y_train = np.load('./Datasets/y_train.npy')\n",
    "y_test = np.load('./Datasets/y_val.npy')\n",
    "with open('./Datasets/class_weights.pkl', 'rb') as file:\n",
    "    loaded_class_weights = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = IMG_SHAPE)\n",
    "base_model.trainable = False\n",
    "model= Sequential()\n",
    "model.add(Rescaling(1./255,input_shape = IMG_SHAPE))\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=('relu'))) \n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(8,activation=('sigmoid')))\n",
    "\n",
    "# Sanity check\n",
    "print(f\"\\nModel input shape:\\n{model.input_shape}\\nModel output shape:\\n\"\\\n",
    "f\"{model.output_shape}\\n\\n\\nModel summary:\") \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is saved at the end of every epoch, if it's the best seen so far.\n",
    "checkpoint_filepath = './Checkpointrun2'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the hyperparameters\n",
    "\n",
    "batch_size= 2**6\n",
    "initial_epochs=5 #15\n",
    "learn_rate=0.001\n",
    "adam = Adam(learning_rate=learn_rate)\n",
    "\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator.flow(X_train, y_train, batch_size= batch_size),\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=(X_val,y_val),\n",
    "                    steps_per_epoch= 20, #len(X_train)/batch_size,\n",
    "                    validation_steps=len(X_val),\n",
    "                    class_weights=loaded_class_weights,\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "# _ , accuracy = model.evaluate(x=X_test,y=y_test,batch_size= batch_size,verbose=1)\n",
    "# print(f'Model accuracy on test set: {round(accuracy,3)*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
