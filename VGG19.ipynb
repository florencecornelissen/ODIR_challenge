{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Rescaling\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv3D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers, optimizers, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import ast\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "from keras.applications import ResNet50\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.saving import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./Datasets/X_train.npy')\n",
    "X_val = np.load('./Datasets/X_val.npy')\n",
    "y_train = np.load('./Datasets/y_train.npy')\n",
    "y_val = np.load('./Datasets/y_val.npy')\n",
    "with open('./Datasets/class_weights.pkl', 'rb') as file:\n",
    "    loaded_class_weights = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model input shape:\n",
      "(None, 224, 224, 3)\n",
      "Model output shape:\n",
      "(None, 8)\n",
      "\n",
      "\n",
      "Model summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26481096 (101.02 MB)\n",
      "Trainable params: 6456712 (24.63 MB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = IMG_SHAPE)\n",
    "base_model.trainable = False\n",
    "model= Sequential()\n",
    "model.add(Rescaling(1./255,input_shape = IMG_SHAPE))\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=('relu'))) \n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(8,activation=('sigmoid')))\n",
    "\n",
    "# Sanity check\n",
    "print(f\"\\nModel input shape:\\n{model.input_shape}\\nModel output shape:\\n\"\\\n",
    "f\"{model.output_shape}\\n\\n\\nModel summary:\") \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is saved at the end of every epoch, if it's the best seen so far.\n",
    "checkpoint_filepath = './Checkpointrun2'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the hyperparameters\n",
    "batch_size= 2**6\n",
    "initial_epochs=15\n",
    "learn_rate=0.001\n",
    "adam = Adam(learning_rate=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size, class_weights):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_X = self.X[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_y = self.y[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        return batch_X, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Optionally shuffle your data here\n",
    "        pass\n",
    "\n",
    "train_generator = CustomDataGenerator(X_train, y_train, batch_size, loaded_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "88/87 [==============================] - ETA: 0s - loss: 2.0942 - accuracy: 0.3576 INFO:tensorflow:Assets written to: ./Checkpointrun2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Checkpointrun2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1235s 14s/step - loss: 2.0942 - accuracy: 0.3576 - val_loss: 1.6797 - val_accuracy: 0.4196\n",
      "Epoch 2/15\n",
      "22/87 [======>.......................] - ETA: 11:57 - loss: 1.7577 - accuracy: 0.3915"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=(X_val,y_val),\n",
    "                    steps_per_epoch= len(X_train)/batch_size,\n",
    "                    validation_steps=len(X_val),\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "# plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "# _ , accuracy = model.evaluate(x=X_test,y=y_test,batch_size= batch_size,verbose=1)\n",
    "# print(f'Model accuracy on test set: {round(accuracy,3)*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
